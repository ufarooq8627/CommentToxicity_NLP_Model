{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce8c8e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import re\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, SpatialDropout1D, Bidirectional, LSTM, GlobalMaxPool1D, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import pickle, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "78ed69a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow[and-cuda] in c:\\users\\farooque\\anaconda3\\lib\\site-packages (2.20.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (2.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (25.12.19)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (0.7.0)\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (18.1.1)\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (24.1)\n",
      "Requirement already satisfied: protobuf>=5.28.0 in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (6.33.5)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (3.3.0)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (4.15.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (1.78.0)\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (2.20.0)\n",
      "Requirement already satisfied: keras>=3.10.0 in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (3.13.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (3.11.0)\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in c:\\users\\farooque\\anaconda3\\lib\\site-packages (from tensorflow[and-cuda]) (0.5.4)\n",
      "Collecting nvidia-cublas-cu12<13.0,>=12.5.3.2 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cublas_cu12-12.9.1.4-py3-none-win_amd64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.9.79-py3-none-win_amd64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cuda-nvcc-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvcc_cu12-12.9.86-py3-none-win_amd64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.9.86-py3-none-win_amd64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12<13.0,>=12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.9.79-py3-none-win_amd64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12<10.0,>=9.3.0.75 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cudnn_cu12-9.19.0.56-py3-none-win_amd64.whl.metadata (1.9 kB)\n",
      "Collecting nvidia-cufft-cu12<12.0,>=11.2.3.61 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cufft_cu12-11.4.1.4-py3-none-win_amd64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-curand-cu12<11.0,>=10.3.6.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_curand_cu12-10.3.10.19-py3-none-win_amd64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12<12.0,>=11.6.3.83 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusolver_cu12-11.7.5.82-py3-none-win_amd64.whl.metadata (1.9 kB)\n",
      "Collecting nvidia-cusparse-cu12<13.0,>=12.5.1.3 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusparse_cu12-12.5.10.65-py3-none-win_amd64.whl.metadata (1.8 kB)\n",
      "INFO: pip is looking at multiple versions of tensorflow[and-cuda] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Using cached tensorflow-2.19.1-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow[and-cuda])\n",
      "  Using cached protobuf-5.29.6-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow[and-cuda])\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12==12.5.3.2 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cublas_cu12-12.5.3.2-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.5.82-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvcc-cu12==12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvcc_cu12-12.5.82-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.5.82-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.5.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.5.82-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.3.0.75 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cudnn_cu12-9.3.0.75-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.3.61 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cufft_cu12-11.2.3.61-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.6.82 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_curand_cu12-10.3.6.82-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.3.83 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusolver_cu12-11.6.3.83-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.5.1.3 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusparse_cu12-12.5.1.3-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "  Using cached tensorflow-2.18.1-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow[and-cuda])\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Using cached tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow[and-cuda])\n",
      "  Using cached tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Using cached tensorflow-2.17.1-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.17.1 (from tensorflow[and-cuda])\n",
      "  Using cached tensorflow_intel-2.17.1-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting nvidia-cublas-cu12==12.3.4.1 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cublas_cu12-12.3.4.1-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.3.101 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_cupti_cu12-12.3.101-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-nvcc-cu12==12.3.107 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvcc_cu12-12.3.107-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.3.107 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_nvrtc_cu12-12.3.107-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.3.101 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cuda_runtime_cu12-12.3.101-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cudnn-cu12==8.9.7.29 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cudnn_cu12-8.9.7.29-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu12==11.0.12.1 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cufft_cu12-11.0.12.1-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.4.107 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_curand_cu12-10.3.4.107-py3-none-win_amd64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.5.4.101 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusolver_cu12-11.5.4.101-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.2.0.103 (from tensorflow[and-cuda])\n",
      "  Using cached nvidia_cusparse_cu12-12.2.0.103-py3-none-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Using cached tensorflow-2.17.0-cp312-cp312-win_amd64.whl.metadata (3.2 kB)\n",
      "Collecting tensorflow-intel==2.17.0 (from tensorflow[and-cuda])\n",
      "  Using cached tensorflow_intel-2.17.0-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Using cached tensorflow-2.16.2-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Collecting tensorflow-intel==2.16.2 (from tensorflow[and-cuda])\n",
      "  Using cached tensorflow_intel-2.16.2-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "INFO: pip is still looking at multiple versions of tensorflow[and-cuda] to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting tensorflow[and-cuda]\n",
      "  Using cached tensorflow-2.16.1-cp312-cp312-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting tensorflow-intel==2.16.1 (from tensorflow[and-cuda])\n",
      "  Using cached tensorflow_intel-2.16.1-cp312-cp312-win_amd64.whl.metadata (5.0 kB)\n",
      "\n",
      "The conflict is caused by:\n",
      "    tensorflow[and-cuda] 2.20.0 depends on nvidia-nccl-cu12<3.0 and >=2.25.1; extra == \"and-cuda\"\n",
      "    tensorflow[and-cuda] 2.19.1 depends on nvidia-nccl-cu12==2.23.4; extra == \"and-cuda\"\n",
      "    tensorflow[and-cuda] 2.19.0 depends on nvidia-nccl-cu12==2.23.4; extra == \"and-cuda\"\n",
      "    tensorflow[and-cuda] 2.18.1 depends on nvidia-nccl-cu12==2.21.5; extra == \"and-cuda\"\n",
      "    tensorflow[and-cuda] 2.18.0 depends on nvidia-nccl-cu12==2.21.5; extra == \"and-cuda\"\n",
      "    tensorflow[and-cuda] 2.17.1 depends on nvidia-nccl-cu12==2.19.3; extra == \"and-cuda\"\n",
      "    tensorflow[and-cuda] 2.17.0 depends on nvidia-nccl-cu12==2.19.3; extra == \"and-cuda\"\n",
      "    tensorflow[and-cuda] 2.16.2 depends on nvidia-nccl-cu12==2.19.3; extra == \"and-cuda\"\n",
      "    tensorflow[and-cuda] 2.16.1 depends on nvidia-nccl-cu12==2.19.3; extra == \"and-cuda\"\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install tensorflow[and-cuda]==2.16.1, tensorflow[and-cuda]==2.16.2, tensorflow[and-cuda]==2.17.0, tensorflow[and-cuda]==2.17.1, tensorflow[and-cuda]==2.18.0, tensorflow[and-cuda]==2.18.1, tensorflow[and-cuda]==2.19.0, tensorflow[and-cuda]==2.19.1 and tensorflow[and-cuda]==2.20.0 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow[and-cuda]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "343a6f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bae1a84a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00001cee341fdb12</td>\n",
       "      <td>Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0000247867823ef7</td>\n",
       "      <td>== From RfC == \\n\\n The title is fine as it is, IMO.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00013b17ad220c46</td>\n",
       "      <td>\" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lapland —&nbsp;&nbsp;/&nbsp;&nbsp;\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00017563c3f7919a</td>\n",
       "      <td>:If you have a look back at the source, the information I updated was the correct form. I can only guess the source hadn't updated. I shall update the information once again but thank you for your message.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00017695ad8997eb</td>\n",
       "      <td>I don't anonymously edit articles at all.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153159</th>\n",
       "      <td>fffcd0960ee309b5</td>\n",
       "      <td>. \\n i totally agree, this stuff is nothing but too-long-crap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153160</th>\n",
       "      <td>fffd7a9a6eb32c16</td>\n",
       "      <td>== Throw from out field to home plate. == \\n\\n Does it get there faster by throwing to cut off man or direct from out fielder? \\n Were the out fielders in the Mickey mantle era have better arms? \\n Rich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153161</th>\n",
       "      <td>fffda9e8d6fafa9e</td>\n",
       "      <td>\" \\n\\n == Okinotorishima categories == \\n\\n I see your changes and agree this is \"\"more correct.\"\"&nbsp;&nbsp;I had gotten confused, but then found this: \\n :... while acknowledging Japan's territorial rights to Okinotorishima itself ... \\n However, is there a category for&nbsp;&nbsp;\\n :... did not acknowledge Japan's claim to an exclusive economic zone (EEZ) stemming from Okinotorishima. \\n That is, is there a category for \"\"disputed EEZ\"\"s?&nbsp;&nbsp; \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153162</th>\n",
       "      <td>fffe8f1340a79fc2</td>\n",
       "      <td>\" \\n\\n == \"\"One of the founding nations of the EU - Germany - has a Law of Return quite similar to Israel's\"\" == \\n\\n This isn't actually true, is it? Germany allows people whose ancestors were citizens of Germany to return, but AFAIK it does not allow the descendants of Anglo-Saxons to \"\"return\"\" to Angeln and Saxony. Israel, by contrast, allows all Jews to \"\"return\"\" to Israel, even if they can't trace a particular ancestral line to anyone who lived in the modern state or even mandate Palestine. — \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153163</th>\n",
       "      <td>ffffce3fb183ee80</td>\n",
       "      <td>\" \\n :::Stop already. Your bullshit is not welcome here. I'm no fool, and if you think that kind of explination is enough, well pity you.&nbsp;&nbsp;&nbsp;&nbsp;\"</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>153164 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  \\\n",
       "0       00001cee341fdb12   \n",
       "1       0000247867823ef7   \n",
       "2       00013b17ad220c46   \n",
       "3       00017563c3f7919a   \n",
       "4       00017695ad8997eb   \n",
       "...                  ...   \n",
       "153159  fffcd0960ee309b5   \n",
       "153160  fffd7a9a6eb32c16   \n",
       "153161  fffda9e8d6fafa9e   \n",
       "153162  fffe8f1340a79fc2   \n",
       "153163  ffffce3fb183ee80   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      comment_text  \n",
       "0                                                                                                                                                  Yo bitch Ja Rule is more succesful then you'll ever be whats up with you and hating you sad mofuckas...i should bitch slap ur pethedic white faces and get you to kiss my ass you guys sicken me. Ja rule is about pride in da music man. dont diss that shit on him. and nothin is wrong bein like tupac he was a brother too...fuckin white boys get things right next time.,  \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                             == From RfC == \\n\\n The title is fine as it is, IMO.  \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                       \" \\n\\n == Sources == \\n\\n * Zawe Ashton on Lapland —  /  \"  \n",
       "3                                                                                                                                                                                                                                                                                                                    :If you have a look back at the source, the information I updated was the correct form. I can only guess the source hadn't updated. I shall update the information once again but thank you for your message.  \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        I don't anonymously edit articles at all.  \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            ...  \n",
       "153159                                                                                                                                                                                                                                                                                                                                                                                                                                                               . \\n i totally agree, this stuff is nothing but too-long-crap  \n",
       "153160                                                                                                                                                                                                                                                                                                                  == Throw from out field to home plate. == \\n\\n Does it get there faster by throwing to cut off man or direct from out fielder? \\n Were the out fielders in the Mickey mantle era have better arms? \\n Rich  \n",
       "153161                                                                             \" \\n\\n == Okinotorishima categories == \\n\\n I see your changes and agree this is \"\"more correct.\"\"  I had gotten confused, but then found this: \\n :... while acknowledging Japan's territorial rights to Okinotorishima itself ... \\n However, is there a category for  \\n :... did not acknowledge Japan's claim to an exclusive economic zone (EEZ) stemming from Okinotorishima. \\n That is, is there a category for \"\"disputed EEZ\"\"s?   \"  \n",
       "153162  \" \\n\\n == \"\"One of the founding nations of the EU - Germany - has a Law of Return quite similar to Israel's\"\" == \\n\\n This isn't actually true, is it? Germany allows people whose ancestors were citizens of Germany to return, but AFAIK it does not allow the descendants of Anglo-Saxons to \"\"return\"\" to Angeln and Saxony. Israel, by contrast, allows all Jews to \"\"return\"\" to Israel, even if they can't trace a particular ancestral line to anyone who lived in the modern state or even mandate Palestine. — \"  \n",
       "153163                                                                                                                                                                                                                                                                                                                                                                              \" \\n :::Stop already. Your bullshit is not welcome here. I'm no fool, and if you think that kind of explination is enough, well pity you.    \"  \n",
       "\n",
       "[153164 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ae480b1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.&nbsp;&nbsp;(talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"&nbsp;&nbsp;-I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport&nbsp;&nbsp;\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>ffe987279560d7ff</td>\n",
       "      <td>\":::::And for the second time of asking, when your view completely contradicts the coverage in reliable sources, why should anyone care what you feel? You can't even give a consistent argument - is the opening only supposed to mention significant aspects, or the \"\"most significant\"\" ones?&nbsp;&nbsp; \\n\\n\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>ffea4adeee384e90</td>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is a horrible thing you put on my talk page.&nbsp;&nbsp;128.61.19.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>ffee36eab5c267c9</td>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for prostitution ring.&nbsp;&nbsp;- Crunch Captain.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>fff125370e4aaaf3</td>\n",
       "      <td>And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>fff46fc426af1f9a</td>\n",
       "      <td>\"\\nAnd ... I really don't think you understand.&nbsp;&nbsp;I came here and my idea was bad right away.&nbsp;&nbsp;What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.&nbsp;&nbsp; \"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id  \\\n",
       "0       0000997932d777bf   \n",
       "1       000103f0d9cfb60f   \n",
       "2       000113f07ec002fd   \n",
       "3       0001b41b1c6bb37e   \n",
       "4       0001d958c54c6e35   \n",
       "...                  ...   \n",
       "159566  ffe987279560d7ff   \n",
       "159567  ffea4adeee384e90   \n",
       "159568  ffee36eab5c267c9   \n",
       "159569  fff125370e4aaaf3   \n",
       "159570  fff46fc426af1f9a   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              comment_text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ...   \n",
       "159566                                                                                                                                                                                                                                                                                                                                           \":::::And for the second time of asking, when your view completely contradicts the coverage in reliable sources, why should anyone care what you feel? You can't even give a consistent argument - is the opening only supposed to mention significant aspects, or the \"\"most significant\"\" ones?   \\n\\n\"   \n",
       "159567                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               You should be ashamed of yourself \\n\\nThat is a horrible thing you put on my talk page.  128.61.19.93   \n",
       "159568                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Spitzer \\n\\nUmm, theres no actual article for prostitution ring.  - Crunch Captain.   \n",
       "159569                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                And it looks like it was actually you who put on the speedy to have the first version deleted now that I look at it.   \n",
       "159570                                                                                                                                                                                                                                                                                                                                                                                                                                                      \"\\nAnd ... I really don't think you understand.  I came here and my idea was bad right away.  What kind of community goes \"\"you have bad ideas\"\" go away, instead of helping rewrite them.   \"   \n",
       "\n",
       "        toxic  severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0           0             0        0       0       0              0  \n",
       "1           0             0        0       0       0              0  \n",
       "2           0             0        0       0       0              0  \n",
       "3           0             0        0       0       0              0  \n",
       "4           0             0        0       0       0              0  \n",
       "...       ...           ...      ...     ...     ...            ...  \n",
       "159566      0             0        0       0       0              0  \n",
       "159567      0             0        0       0       0              0  \n",
       "159568      0             0        0       0       0              0  \n",
       "159569      0             0        0       0       0              0  \n",
       "159570      0             0        0       0       0              0  \n",
       "\n",
       "[159571 rows x 8 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe39fb53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duplicates in the data =  0\n",
      "<class 'pandas.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 8 columns):\n",
      " #   Column         Non-Null Count   Dtype\n",
      "---  ------         --------------   -----\n",
      " 0   id             159571 non-null  str  \n",
      " 1   comment_text   159571 non-null  str  \n",
      " 2   toxic          159571 non-null  int64\n",
      " 3   severe_toxic   159571 non-null  int64\n",
      " 4   obscene        159571 non-null  int64\n",
      " 5   threat         159571 non-null  int64\n",
      " 6   insult         159571 non-null  int64\n",
      " 7   identity_hate  159571 non-null  int64\n",
      "dtypes: int64(6), str(2)\n",
      "memory usage: 72.2 MB\n",
      "\n",
      "Data Info :-  \n",
      " None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\nDuplicates in the data = \", df_train.duplicated().sum())\n",
    "print(\"\\nData Info :- \",\"\\n\",df_train.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3d9353ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_text(text):\n",
    "   \n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "\n",
    "    # remove Wikipedia markup\n",
    "    text = re.sub(r\"={2,}\", \" \", text)\n",
    "    text = re.sub(r\":{2,}\", \" \", text)\n",
    "    # remove escaped newlines\n",
    "    text = re.sub(r\"\\\\n|\\\\t|\\\\r\", \" \", text)\n",
    "    text = re.sub(r\"\\n|\\t|\\r\", \" \", text)\n",
    "\n",
    "    # remove URLs\n",
    "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", \"\", text)\n",
    "\n",
    "    # remove HTML tags\n",
    "    text = re.sub(r\"<.*?>\", \"\", text)\n",
    "\n",
    "    # remove punctuation\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "\n",
    "    # remove numbers\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "    # remove extra spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2dbda421",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['clean_comment'] = df_train['comment_text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e5417cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "12ac7c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "      <td>159571.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.095844</td>\n",
       "      <td>0.009996</td>\n",
       "      <td>0.052948</td>\n",
       "      <td>0.002996</td>\n",
       "      <td>0.049364</td>\n",
       "      <td>0.008805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.294379</td>\n",
       "      <td>0.099477</td>\n",
       "      <td>0.223931</td>\n",
       "      <td>0.054650</td>\n",
       "      <td>0.216627</td>\n",
       "      <td>0.093420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               toxic   severe_toxic        obscene         threat  \\\n",
       "count  159571.000000  159571.000000  159571.000000  159571.000000   \n",
       "mean        0.095844       0.009996       0.052948       0.002996   \n",
       "std         0.294379       0.099477       0.223931       0.054650   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "              insult  identity_hate  \n",
       "count  159571.000000  159571.000000  \n",
       "mean        0.049364       0.008805  \n",
       "std         0.216627       0.093420  \n",
       "min         0.000000       0.000000  \n",
       "25%         0.000000       0.000000  \n",
       "50%         0.000000       0.000000  \n",
       "75%         0.000000       0.000000  \n",
       "max         1.000000       1.000000  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "860c7830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            15294\n",
       "severe_toxic      1595\n",
       "obscene           8449\n",
       "threat             478\n",
       "insult            7877\n",
       "identity_hate     1405\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "159571"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this shows how many 1's are there in the whole column\n",
    "display(df_train[['toxic','severe_toxic','obscene','threat','insult','identity_hate']].sum())\n",
    "display(len(df_train))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "35e5ee26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               count     ratio\n",
      "toxic          15294  0.095844\n",
      "obscene         8449  0.052948\n",
      "insult          7877  0.049364\n",
      "severe_toxic    1595  0.009996\n",
      "identity_hate   1405  0.008805\n",
      "threat           478  0.002996\n"
     ]
    }
   ],
   "source": [
    "cmt_labels = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']\n",
    "\n",
    "freq = df_train[cmt_labels].sum().sort_values(ascending=False)\n",
    "ratio = freq / len(df_train)\n",
    "\n",
    "imbalance_df = pd.DataFrame({\n",
    "    \"count\": freq,\n",
    "    \"ratio\": ratio\n",
    "})\n",
    "print(imbalance_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0b2deac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after running the above code we found that only small percentage of the data has toxic values, severe_toxic, threat etc. \n",
    "# So most comments are non toxic, so lazy model will detect that every comment is clean and still look accurate.\n",
    "# as we can see the the data is very imbalanced and the data skewed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e6c5ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we balance the data first then and split the data later copies of the same comment can land on both training and test. \n",
    "# The model then sees the twin of the test example during training then the model overfits(Data leakage)\n",
    "\n",
    "#        Remembering\n",
    "# original data\n",
    "# → split\n",
    "# → balance training only\n",
    "# → evaluate on untouched test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b1d3318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = df_train['clean_comment']\n",
    "y = df_train[cmt_labels]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    x,y,\n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2173962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140030    1_0_0_0_0_0\n",
       "159124    0_0_0_0_0_0\n",
       "60006     0_0_0_0_0_0\n",
       "65432     0_0_0_0_0_0\n",
       "154979    0_0_0_0_0_0\n",
       "             ...     \n",
       "119879    0_0_0_0_0_0\n",
       "103694    0_0_0_0_0_0\n",
       "131932    1_0_0_0_0_0\n",
       "146867    0_0_0_0_0_0\n",
       "121958    0_0_0_0_0_0\n",
       "Length: 127656, dtype: str"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_combo = y_train.astype(str).agg('_'.join, axis=1)\n",
    "y_train_combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "71f28d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "counts = y_train_combo.value_counts()\n",
    "\n",
    "majority_class = counts.idxmax()\n",
    "\n",
    "sampling_strategy = {\n",
    "    majority_class: 15000   # choose a reasonable cap\n",
    "}\n",
    "\n",
    "rus = RandomUnderSampler(\n",
    "    sampling_strategy=sampling_strategy,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "X_under, y_under_combo = rus.fit_resample(\n",
    "    X_train.to_frame(),\n",
    "    y_train_combo\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "111da153",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_under = y_under_combo.str.split('_', expand=True).astype(int)\n",
    "y_under.columns = y_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ea6829aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic            12238\n",
       "severe_toxic      1274\n",
       "obscene           6734\n",
       "threat             404\n",
       "insult            6263\n",
       "identity_hate     1111\n",
       "dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_under.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "699f5362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0_0_0_0_0_0    114675\n",
       "1_0_0_0_0_0      4589\n",
       "1_0_1_0_1_0      3023\n",
       "1_0_1_0_0_0      1399\n",
       "1_0_0_0_1_0       953\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_combo.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60b392ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model with RUS\n",
    "\n",
    "\n",
    "vectoriser = TfidfVectorizer(max_features=50000, ngram_range=(1,2))\n",
    "X_train_vector = vectoriser.fit_transform(X_under['clean_comment'])\n",
    "X_test_vector = vectoriser.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db8a1366",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_combo = y_under.astype(str).agg('_'.join, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5c045569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: (27981, 50000)\n",
      "After SMOTE: (31486, 50000)\n",
      "\n",
      "Toxic class distribution after SMOTE:\n",
      "toxic\n",
      "0    15743\n",
      "1    15743\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply SMOTE using 'toxic' as the target (binary, both classes have thousands of samples)\n",
    "smote = SMOTE(k_neighbors=3, random_state=42)\n",
    "\n",
    "X_smote, y_smote_toxic = smote.fit_resample(X_train_vector, y_under['toxic'])\n",
    "\n",
    "print(\"Before SMOTE:\", X_train_vector.shape)\n",
    "print(\"After SMOTE:\", X_smote.shape)\n",
    "print(\"\\nToxic class distribution after SMOTE:\")\n",
    "print(y_smote_toxic.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da6363a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train a OneVsRest Logistic Regression on SMOTE-balanced data\n",
    "# Note: y_under has all 6 labels aligned with X_train_vector rows\n",
    "model = OneVsRestClassifier(LogisticRegression(max_iter=1000, random_state=42))\n",
    "model.fit(X_smote, y_smote_toxic)\n",
    "\n",
    "print(\"Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "98f5385b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained on all 6 labels!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train on the original undersampled data (all 6 labels)\n",
    "model = OneVsRestClassifier(\n",
    "    LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    ")\n",
    "model.fit(X_train_vector, y_under)\n",
    "\n",
    "print(\"Model trained on all 6 labels!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8100ecb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.53      0.86      0.66      3056\n",
      " severe_toxic       0.33      0.71      0.45       321\n",
      "      obscene       0.75      0.80      0.77      1715\n",
      "       threat       0.29      0.73      0.41        74\n",
      "       insult       0.60      0.81      0.69      1614\n",
      "identity_hate       0.32      0.66      0.43       294\n",
      "\n",
      "    micro avg       0.55      0.82      0.66      7074\n",
      "    macro avg       0.47      0.76      0.57      7074\n",
      " weighted avg       0.58      0.82      0.67      7074\n",
      "  samples avg       0.07      0.08      0.07      7074\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FAROOQUE\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\FAROOQUE\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\FAROOQUE\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_pred = model.predict(X_test_vector)\n",
    "\n",
    "print(classification_report(y_test, y_pred, target_names=cmt_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd806c8b",
   "metadata": {},
   "source": [
    "LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059f9d79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fa3adbf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (127656, 200)\n",
      "Test shape: (31915, 200)\n"
     ]
    }
   ],
   "source": [
    "MAX_WORDS = 50000\n",
    "MAX_LEN = 200\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=MAX_LEN, padding='post')\n",
    "X_test_seq = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=MAX_LEN, padding='post')\n",
    "\n",
    "print(\"Train shape:\", X_train_seq.shape)\n",
    "print(\"Test shape:\", X_test_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cdb50c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FAROOQUE\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:100: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_1             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_1          │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout1d_1             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_max_pooling1d_1          │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Embedding(MAX_WORDS, 128, input_length=MAX_LEN),\n",
    "    SpatialDropout1D(0.3),\n",
    "    Bidirectional(LSTM(64, return_sequences=True)),\n",
    "    GlobalMaxPool1D(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(6, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "bfbd4b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 542ms/step - accuracy: 0.7590 - loss: 0.1048 - val_accuracy: 0.9940 - val_loss: 0.0546 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 544ms/step - accuracy: 0.9701 - loss: 0.0497 - val_accuracy: 0.9940 - val_loss: 0.0512 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m246s\u001b[0m 548ms/step - accuracy: 0.9870 - loss: 0.0439 - val_accuracy: 0.9940 - val_loss: 0.0513 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539ms/step - accuracy: 0.9809 - loss: 0.0404\n",
      "Epoch 4: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m248s\u001b[0m 553ms/step - accuracy: 0.9804 - loss: 0.0403 - val_accuracy: 0.9940 - val_loss: 0.0534 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m449/449\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m247s\u001b[0m 550ms/step - accuracy: 0.9711 - loss: 0.0365 - val_accuracy: 0.9940 - val_loss: 0.0532 - learning_rate: 5.0000e-04\n",
      "Epoch 5: early stopping\n",
      "Restoring model weights from the end of the best epoch: 2.\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, min_lr=1e-6, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train_seq, y_train.values,\n",
    "    validation_split=0.1,\n",
    "    batch_size=256,\n",
    "    epochs=10,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "48b76119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m998/998\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 21ms/step\n",
      "=== Classification Report ===\n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "        toxic       0.88      0.73      0.80      3056\n",
      " severe_toxic       0.72      0.07      0.12       321\n",
      "      obscene       0.83      0.75      0.79      1715\n",
      "       threat       0.00      0.00      0.00        74\n",
      "       insult       0.73      0.68      0.71      1614\n",
      "identity_hate       0.00      0.00      0.00       294\n",
      "\n",
      "    micro avg       0.83      0.66      0.73      7074\n",
      "    macro avg       0.53      0.37      0.40      7074\n",
      " weighted avg       0.78      0.66      0.70      7074\n",
      "  samples avg       0.06      0.06      0.06      7074\n",
      "\n",
      "\n",
      "=== AUC-ROC Scores ===\n",
      "\n",
      "  toxic           AUC-ROC: 0.9748\n",
      "  severe_toxic    AUC-ROC: 0.9874\n",
      "  obscene         AUC-ROC: 0.9894\n",
      "  threat          AUC-ROC: 0.9560\n",
      "  insult          AUC-ROC: 0.9824\n",
      "  identity_hate   AUC-ROC: 0.9577\n",
      "\n",
      "  Overall (macro) AUC-ROC: 0.9746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FAROOQUE\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\FAROOQUE\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\FAROOQUE\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\FAROOQUE\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = model.predict(X_test_seq)\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "print(\"=== Classification Report ===\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=cmt_labels))\n",
    "\n",
    "print(\"\\n=== AUC-ROC Scores ===\\n\")\n",
    "for i, label in enumerate(cmt_labels):\n",
    "    auc = roc_auc_score(y_test[label], y_pred_proba[:, i])\n",
    "    print(f\"  {label:15s} AUC-ROC: {auc:.4f}\")\n",
    "\n",
    "overall_auc = roc_auc_score(y_test, y_pred_proba, average='macro')\n",
    "print(f\"\\n  Overall (macro) AUC-ROC: {overall_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1dd8bc2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Metrics saved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\FAROOQUE\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\FAROOQUE\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\FAROOQUE\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "c:\\Users\\FAROOQUE\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "metrics = {\n",
    "    \"classification_report\": classification_report(y_test, y_pred, target_names=cmt_labels, output_dict=True),\n",
    "    \"auc_roc_scores\": {label: round(roc_auc_score(y_test[label], y_pred_proba[:, i]), 4) for i, label in enumerate(cmt_labels)},\n",
    "    \"training_history\": {\n",
    "        \"loss\": [float(x) for x in history.history['loss']],\n",
    "        \"val_loss\": [float(x) for x in history.history['val_loss']],\n",
    "        \"accuracy\": [float(x) for x in history.history['accuracy']],\n",
    "        \"val_accuracy\": [float(x) for x in history.history['val_accuracy']],\n",
    "    }\n",
    "}\n",
    "with open(\"model/metrics.json\", \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print(\"✅ Metrics saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "26958137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model and tokenizer saved to model/ directory\n"
     ]
    }
   ],
   "source": [
    "\n",
    "os.makedirs(\"model\", exist_ok=True)\n",
    "model.save(\"model/toxicity_model.keras\")\n",
    "\n",
    "with open(\"model/tokenizer.pickle\", \"wb\") as f:\n",
    "    pickle.dump(tokenizer, f)\n",
    "\n",
    "print(\"✅ Model and tokenizer saved to model/ directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc104e92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
